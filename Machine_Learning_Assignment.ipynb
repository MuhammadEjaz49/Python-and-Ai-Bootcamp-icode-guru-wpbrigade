{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfupl7r8XiaD",
        "outputId": "e44ba2e1-a9cb-4afe-a591-4d7322b4800e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape after cleaning: (16598, 11)\n",
            "KNN baseline accuracy: 0.296\n",
            "DecisionTree baseline accuracy: 0.257\n",
            "RandomForest baseline accuracy: 0.292\n",
            "KNN tuned accuracy: 0.302, best params: {'model__weights': 'uniform', 'model__n_neighbors': 11}\n",
            "DecisionTree tuned accuracy: 0.308, best params: {'model__min_samples_split': 10, 'model__max_depth': 10}\n",
            "RandomForest tuned accuracy: 0.339, best params: {'model__n_estimators': 300, 'model__min_samples_split': 10, 'model__max_depth': None}\n",
            "Report saved: ML_Assignment_Report.docx\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, label_binarize\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from docx import Document\n",
        "from docx.shared import Inches, Pt\n",
        "from datetime import datetime\n",
        "\n",
        "# =========================\n",
        "# 1. Load and clean dataset\n",
        "# =========================\n",
        "dataset_path = \"/content/vgsalesGlobale.csv\"   # make sure this file is in the same folder\n",
        "plots_dir = \"plots\"\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(dataset_path)\n",
        "df['Year'] = pd.to_numeric(df.get('Year'), errors='coerce')\n",
        "df = df.dropna(subset=['Genre'])\n",
        "df['Publisher'] = df['Publisher'].fillna('Unknown')\n",
        "df['Year'] = df['Year'].fillna(int(np.nanmedian(df['Year'])))\n",
        "for c in [c for c in df.columns if c.endswith('_Sales')]:\n",
        "    df[c] = df[c].fillna(0)\n",
        "df = df.drop_duplicates()\n",
        "print(\"Data shape after cleaning:\", df.shape)\n",
        "\n",
        "# =========================\n",
        "# 2. Exploratory Data Analysis\n",
        "# =========================\n",
        "plt.figure()\n",
        "df['Global_Sales'].plot(kind='hist', bins=40, alpha=0.8)\n",
        "plt.title('Distribution of Global Sales (Millions)')\n",
        "plt.xlabel('Global_Sales')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, \"global_sales_hist.png\"))\n",
        "plt.close()\n",
        "\n",
        "top_genre = df.groupby('Genre')['Global_Sales'].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "plt.figure()\n",
        "plt.bar(top_genre['Genre'], top_genre['Global_Sales'])\n",
        "plt.title('Top 10 Genres by Global Sales')\n",
        "plt.xlabel('Genre'); plt.ylabel('Total Global Sales (Millions)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, \"top_genres_global_sales.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Interactive Plotly chart\n",
        "top_pub = df.groupby('Publisher')['Global_Sales'].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "fig = px.bar(top_pub, x='Publisher', y='Global_Sales', title='Top 10 Publishers by Global Sales (Interactive)')\n",
        "fig.write_html(\"interactive_top_publishers.html\")\n",
        "\n",
        "# =========================\n",
        "# 3. Feature Engineering\n",
        "# =========================\n",
        "y = df['Genre'].values\n",
        "numeric_features = ['Year'] + [c for c in df.columns if c.endswith('_Sales') and c!='Global_Sales']\n",
        "categorical_features = ['Platform']\n",
        "\n",
        "# Limit publisher categories\n",
        "N = 20\n",
        "top_publishers = df['Publisher'].value_counts().head(N).index\n",
        "df['Publisher_limited'] = np.where(df['Publisher'].isin(top_publishers), df['Publisher'], 'Other')\n",
        "categorical_features.append('Publisher_limited')\n",
        "\n",
        "X = df[numeric_features + categorical_features].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "numeric_transformer = Pipeline([('scaler', StandardScaler())])\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# =========================\n",
        "# 4. Baseline Models\n",
        "# =========================\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "baseline_results = {}\n",
        "for name, clf in models.items():\n",
        "    pipe = Pipeline([('preprocess', preprocess), ('model', clf)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    baseline_results[name] = {\n",
        "        \"accuracy\": acc,\n",
        "        \"report\": classification_report(y_test, y_pred),\n",
        "        \"confusion_matrix\": confusion_matrix(y_test, y_pred)\n",
        "    }\n",
        "    print(f\"{name} baseline accuracy: {acc:.3f}\")\n",
        "\n",
        "# =========================\n",
        "# 5. Feature Importance (RF)\n",
        "# =========================\n",
        "rf_pipe = Pipeline([('preprocess', preprocess), ('model', RandomForestClassifier(random_state=42))])\n",
        "rf_pipe.fit(X_train, y_train)\n",
        "rf_model = rf_pipe.named_steps['model']\n",
        "ohe = rf_pipe.named_steps['preprocess'].named_transformers_['cat']\n",
        "feature_names = numeric_features + list(ohe.get_feature_names_out(categorical_features))\n",
        "importances = rf_model.feature_importances_\n",
        "fi_df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "plt.figure()\n",
        "plt.barh(fi_df[\"feature\"].head(15)[::-1], fi_df[\"importance\"].head(15)[::-1])\n",
        "plt.title(\"Top 15 Feature Importances (Random Forest)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, \"rf_feature_importances_top15.png\"))\n",
        "plt.close()\n",
        "\n",
        "# =========================\n",
        "# 6. Hyperparameter Tuning\n",
        "# =========================\n",
        "tuned_results = {}\n",
        "\n",
        "# KNN\n",
        "knn_pipe = Pipeline([('preprocess', preprocess), ('model', KNeighborsClassifier())])\n",
        "knn_dist = {\"model__n_neighbors\": range(3, 21, 2), \"model__weights\": [\"uniform\", \"distance\"]}\n",
        "knn_search = RandomizedSearchCV(knn_pipe, knn_dist, n_iter=5, cv=3, scoring=\"accuracy\", random_state=42, n_jobs=-1)\n",
        "knn_search.fit(X_train, y_train)\n",
        "tuned_results[\"KNN\"] = knn_search\n",
        "\n",
        "# Decision Tree\n",
        "dt_pipe = Pipeline([('preprocess', preprocess), ('model', DecisionTreeClassifier(random_state=42))])\n",
        "dt_dist = {\"model__max_depth\": [None, 10, 20, 30], \"model__min_samples_split\": [2, 5, 10]}\n",
        "dt_search = RandomizedSearchCV(dt_pipe, dt_dist, n_iter=5, cv=3, scoring=\"accuracy\", random_state=42, n_jobs=-1)\n",
        "dt_search.fit(X_train, y_train)\n",
        "tuned_results[\"DecisionTree\"] = dt_search\n",
        "\n",
        "# Random Forest\n",
        "rf_pipe = Pipeline([('preprocess', preprocess), ('model', RandomForestClassifier(random_state=42))])\n",
        "rf_dist = {\"model__n_estimators\": [100, 200, 300], \"model__max_depth\": [None, 10, 20], \"model__min_samples_split\": [2, 5, 10]}\n",
        "rf_search = RandomizedSearchCV(rf_pipe, rf_dist, n_iter=5, cv=3, scoring=\"accuracy\", random_state=42, n_jobs=-1)\n",
        "rf_search.fit(X_train, y_train)\n",
        "tuned_results[\"RandomForest\"] = rf_search\n",
        "\n",
        "for name, search in tuned_results.items():\n",
        "    acc = accuracy_score(y_test, search.predict(X_test))\n",
        "    print(f\"{name} tuned accuracy: {acc:.3f}, best params: {search.best_params_}\")\n",
        "\n",
        "# =========================\n",
        "# 7. ROC Curve (best tuned model)\n",
        "# =========================\n",
        "best_model_name = max(tuned_results, key=lambda k: accuracy_score(y_test, tuned_results[k].predict(X_test)))\n",
        "best_pipe = tuned_results[best_model_name].best_estimator_\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "y_test_bin = label_binarize(y_test, classes=classes)\n",
        "\n",
        "if hasattr(best_pipe.named_steps['model'], \"predict_proba\"):\n",
        "    y_score = best_pipe.predict_proba(X_test)\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "    plt.plot([0,1],[0,1],'--')\n",
        "    plt.title(f\"ROC Curve (micro-average) - {best_model_name}\")\n",
        "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(plots_dir, f\"roc_curve_{best_model_name}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# 8. Generate Report (DOCX)\n",
        "# =========================\n",
        "doc = Document()\n",
        "doc.add_heading(\"ML Assignment Report: Video Game Genre Prediction\", level=1)\n",
        "doc.add_paragraph(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
        "doc.add_paragraph(f\"Dataset size: {df.shape}\")\n",
        "\n",
        "doc.add_heading(\"EDA\", level=2)\n",
        "doc.add_paragraph(\"Global sales distribution is skewed; a few games dominate sales.\")\n",
        "doc.add_paragraph(\"Genres differ in sales totals (see plots).\")\n",
        "\n",
        "doc.add_heading(\"Models\", level=2)\n",
        "for name, res in baseline_results.items():\n",
        "    doc.add_paragraph(f\"{name} baseline accuracy: {res['accuracy']:.3f}\")\n",
        "for name, search in tuned_results.items():\n",
        "    acc = accuracy_score(y_test, search.predict(X_test))\n",
        "    doc.add_paragraph(f\"{name} tuned accuracy: {acc:.3f}\")\n",
        "\n",
        "doc.add_heading(\"Best Model\", level=2)\n",
        "doc.add_paragraph(f\"Best tuned model: {best_model_name}\")\n",
        "\n",
        "doc.save(\"ML_Assignment_Report.docx\")\n",
        "print(\"Report saved: ML_Assignment_Report.docx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5849c872",
        "outputId": "99b5821f-59f3-451f-f3da-67e0d571267a"
      },
      "source": [
        "%pip install python-docx"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.14.1)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/253.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ]
    }
  ]
}